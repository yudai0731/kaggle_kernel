# 1st place solution
Posted in mercari-price-suggestion-challenge 3 years ago

Link : https://www.kaggle.com/c/mercari-price-suggestion-challenge/discussion/50256

みなさんこんにちわ,素晴らしいコンペティションをありがとうございます.Konstantinと一緒に,私たちは非常に興奮しています.おそらく,私たちのソリューションをより詳細に説明するには多すぎると思いますが,明日はもっと書きます.

しかしながら,あなたの食欲をそそるものがあります.Konstantinは素晴らしい仕事をしてくれて,3ヶ月間の私たちの仕事に基づいて非常に小さなカーネルを作成してくれました.

https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s

UPDATE 2

Link to solution https://github.com/pjankiewicz/mercari-solution

UPDATE

# Full description
# Pawel’s premerge solution (~0.3950)
Konstantinとチームを組む前に,私はかなり複雑なモデルを持っていました.それは3つのパーツで構成されていました:
  
モデルごとのカテゴリ - 私はカテゴリレベル1,2,3,カテゴリ2＋配送,item_condition_idなどの組み合わせでリッジモデルを作成しました.これらのモデルはトレーニングが非常に速く,約20分で0.4050のソリューションを作成しました.  
残留モデルMLP - 1に基づいて,私は疎な入力(ニューラルネットワーク)上で次のモデルを訓練した,ターゲットは,予測値と実際の価格の差(ブーストを考えるが,強力なモデルで)であった.
  
残留モデルLGBM - 2と同じ考え方.
カテゴリごとにモデルを学習するというコンセプトは良いように思えますが,実際はそうではありません.このようにモデルを訓練するのはクールですが,使用しているモデルを過小評価してしまいます.ニューラルネットワークは,カテゴリと説明,ブランドなどの間の相互作用を理解するために訓練することはできないと考えることができます.これは間違った仮定です.我々の例では,うまく調整された単一のニューラルネットワークが,それが望むものを学習できることを示している.

# Konstantin’s premerge solution. (~0.3920)
マージ前は2つのベースモデルを持っていました:
  
Tensorflowで実装されたスパースMLPは,私は特徴の数だけを微調整したパブリックカーネルと比較して,洗練された特徴なしで,そしてリッジモデルのeli5の説明を使用してトークナイザーを使用しています.3つのモデルを順次学習した.
多くのカーネルにあったものに似たconv1dを使ったCNNをKerasで実装した.モデル自体は素晴らしいものではなかったが,MLPモデルとは大きく異なるので,良い後押しをしてくれた.
# The merge
合流の瞬間,Konstantinが一位で,私が二位だった 誰かが「なぜ合併したのか」と言うでしょう.しかし,私たちは合併しましたし,それは良い決断でした.成功するためには,やみくもに2つのソリューションをマージするだけでは不十分だと思っていました.実際には,お互いのアイデアを使った1つのソリューションを作らなければなりませんでした.制約の中でそれを実現するのは非常に難しいことでした.時間はそれほど大きな問題ではなく,メモリと4つのニューラルネットワークを同時に実行できることに重点を置いていました.
  
統一されたソリューションを思いつくまでに2週間ほどかかりました（おそらくこの時点で一番頑張っていたと思います）.2つの異なる前処理スキーム(2つのデータセット)が,必要とされていた分散が解に生じていたことが判明し,0.01の改善を簡単に行うことができました.
  
最終的には,3つのデータセットと4つのモデルを各データセットで使用しました.モデルの多様化を試みました.
  
異なるtokenization,with/without stemming
countvectorizer / tfidfvectorizer
# Build system
ソリューションをモジュールに分割する方法がなければ,このプロジェクトを管理することは不可能でした.私たちは独自にコード用のビルドシステムを作成しました.最終的には,ソリューションと一緒にPythonパッケージを作成するシステムを使用しました.私たちのスクリプトは奇妙なもので,次のように見えました（擬似コード）.
  
ENCODED_FILES = {some base64 encoded characters}.
DECODE_FILES 
メルカリパッケージの取り付け
メイン機能の実行
Pythonは一部の操作（特にデータの前処理）をするとメモリがきれいにならない傾向があるので,3つの処理でモデルを連続して実行することは本当に重要でした.

# Feature preprocessing
いくつかのトリック/ノートリックが機能しました.
  
name chargrams - 正確な理由はわかりませんが,名前のn-gramを使うとスコアが改善されました.比較的密度の高い特徴を生成していたからかもしれません.
stemming - 標準の PorterStemmer を使用しました.
数値ベクトル化 - 私たちは,非常に大きなエラーの原因が,次のような記述を持つバンドル項目であることに気づきました."10データ5科学者」のような記述のあるバンドル項目が,データ=10,科学者=5にベクトル化されていることに気づきました.このベクトル化を1つのデータセットに適用しただけで,アンサンブルが0.001改善されました.このアイデアをさらにテストする時間はあまりありませんでした.
text concatenation - テキストフィールドを連結するだけで,テキストフィールドの次元を減らすために,すべての設定{name, item_description, category, brand}をテストしました. これが0.37xxプッシュの理由でした.
追加機能のエンジニアリングについて私たちが持っていた素晴らしいアイデアは何であれ,うまくいきませんでした.いくつか挙げてみましょう.
  
``for [Name]``のような機能の抽出.多くの項目が特定の人に指定されていることに気づきました.それが正確に何を意味するのかはわかりませんでしたが,機能を作成するには十分に重要なことのように思えました.nltkから名前のリストを作成し,AhoCorasickアルゴリズムで類似の文字列を検索しました.
説明文の改行に問題があることに気づきました.誰かが説明文の中で改行を使用した場合,それはどこでもlikeethisのような単語を連結していました.
スペルチェックです.
Pawelを引用します.
ニューラルネットワークは "OK I guess I can use your feature engineering here you are 0.0003 increase "のようなものです.
  
# Models
Pawelは,適切にチューニングされたスパースMLPモデルでは,同じモデルを異なるデータセットで学習するよりも,同じモデルを異なるデータセットで学習した方が,アンサンブルの多様性を達成することができることを発見しました.そこで,私たちは1つのモデルに固執することにしました.ベースモデルは,疎な入力を持つ多層フィードフォワード・ニューラルネットワークです.データセットが大きいので,モデルは大きな容量を持ち,特徴の相互作用を捉えることができなければなりません.データセットが大きいので,モデルは大きな容量を持ち,特徴の相互作用を捉えることができなければならない.しかし,conv1d CNNが埋め込みサイズ32の4コアで学習できる時間で,我々は256の隠しサイズを持つ4つのMLPモデルを学習することができた.
  
慎重な学習スケジュールの調整が重要である：最も重要なことは，各エポックの後にバッチサイズを2倍にすることで，各エポックの後にモデルの学習を高速化し，最終的な性能を向上させることができたことである．また,バッチサイズの増加に加えて,学習率を下げました.2回目のエポックで最高の検証スコアを得て,3回目のエポックでオーバーフィットするように調整しました：これにより,アンサンブルの中でモデルがより強くなりました.
  
カーネル(https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s)のモデルと比較して,我々はいくつかの追加の調整を行いました.
  
使用したモデルには2つのバリエーションがありました：1つはHuber loss（外れ値に対する感度が低いので,ここではより良い）で訓練したもので,もう1つは回帰の代わりに分類を行ったものです.分類については,すべての価格を64のバケットに分割し,予測のためのソフトターゲットを作成しました：最初にバケットの中心からのL2距離を計算し,これにsoftmaxを適用しました（ハイパーパラメータであるsoftmax温度を高く設定）.この分類モデルは,オーバーフィットが少なく,多様性も加えられているため,単独ではより良いスコアを得ることができました.
各データセットの4つのモデルのうち2つについては,学習時と予測時に入力データを2値化し,0以外の値をすべて1にしました. これは,TFIDFの代わりにバイナリCountVectorizerで余分なデータセットをタダで手に入れたようなものです.素晴らしいアイデアだと思います.また,ゼロではないしきい値を使って二値化を試みましたが,あまり改善されませんでした.
また,TensorflowモデルはRELUではなくPRELU活性化を使った方がうまくいきました.
モデルの実装と最適化：このデータセットサイズでは非常に厳しい制約のあるカーネル競合であるため,トレーニングを最大限効率的に行うことが重要でした：最初の隠れ層を大きくすることでスコアを向上させることができました.最終的には,約200kの特徴量に対して256の隠しサイズを持つ12のモデルを学習することができました.以下にその方法を紹介します.
  
TFは複数のコアを使用することができますが,線形スケーリングとは程遠いものです.そこで,各モデルに1つのコアを使用し,4つのモデルを並行して学習した方が良いでしょう.
MXNet はスパース更新をサポートしているので,より効率的な CPU によるスパース MLP の実装が可能であることがわかりました (もしかしたら TF にもあるかもしれませんが,私たちはそれを使うことができませんでした).PawelはMXNetの初期バージョンを書きましたが,それは約2倍高速で,その後,TFのモデルからすべての機能を追加して,さらに良く動作するようにしました.問題はMXNetの実行エンジンがスレッドセーフではないことでした.スレッドを使って並列化しようとすると,1つのコアが使用されるか,セグメンテーションフォールトが発生します.そこで私たちはマルチプロセッシングに移行し,独自のデータジェネレータも書かなければなりませんでした.また,データを共有メモリに入れるバージョンもありましたが,それはディスク容量の制限に近すぎたので,それをスクラッチしなければなりませんでした.
全体的にMXNetソリューションの方が高速で,速度を落とすことなく初期バッチサイズを小さくすることができましたが,より多くのメモリを使用し,信頼性が低いように見えました.1つはMXNet (0.37758 プライベート LB / 0.37665 パブリック),もう1つはTF (0.38006 プライベート / 0.37920 パブリック)でした.
  
最後に,12個の予測があり,それらをマージする必要がありました.平均はうまく機能しましたが,ブレンドの重みを調整する方が良いので,検証にデータセットの1％（局所的には5％）を使用し,Lassoモデルを使用して重みを調整しました.LassoはL1正則化を使用しているので,何かアイデアがあってモデルを追加したときに,Lassoは次のように言ってきます: meh, I don't want your new models, and set their weight to zero.
  
うまくいかなかったモデル
  
MoE (mixture of experts): これは本当にクールな論文 https://arxiv.org/abs/1701.06538 で,同じ計算量を使いながら,より多くの容量を持つモデルを訓練する方法を説明しています: まさに私たちがここで望んでいることです! しかし,最終的には,TF
  
# Meta Statistics
Slack messages: 4500  
Git commits: 152 (317 across all branches)  
PR merged: 31  
Python LOC: 2015  